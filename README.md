# ğŸ¬ MovieLab â€“ AI-Powered Movie Generation  

ğŸš€ **MovieLab** is an AI-driven platform that transforms simple text prompts into cinematic experiences. From scriptwriting to scene generation, our technology enables anyoneâ€”filmmakers, storytellers, and AI enthusiastsâ€”to bring their vision to life through AI-powered storytelling.  

---

## ğŸ“½ï¸ Features  

âœ… **AI-Powered Scriptwriting** â€“ Generate compelling scripts from a single prompt.  
âœ… **OpenAI-Powered Image Analysis** â€“ Detects gender, age, and scene context to match the best voice.  
âœ… **Voice Matching & Lip Syncing** â€“ Ensures accurate speech synchronization for realistic dialogues.  
âœ… **Scene Merging for Extended Videos** â€“ Seamlessly combines up to **4 scenes** for **20-second videos**.  
âœ… **Multi-Model AI Pipeline** â€“ Integrates multiple AI models to generate high-quality video content.  
âœ… **Next.js Backend** â€“ Fast, scalable, and efficient for API handling and UI interactions.  

---

## ğŸ› ï¸ How It Works  

1ï¸âƒ£ **OpenAI Image Analysis & Conversation Extraction**  
- Uses OpenAI's **vision model** to analyze an **uploaded image** and extract details such as **gender, age, and scene context**.  
- Determines the appropriate **voice type** for narration.  
- Extracts key dialogues and conversations from the input prompt.  

2ï¸âƒ£ **AI Model Integration**  
- ğŸï¸ **Video Generation**: Uses **fal-ai/kling-video/v1.6/pro/image-to-video** to create scenes.  
- ğŸ—£ï¸ **Lip-Sync & Animation**: Applies **fal-ai/latentsync** for accurate lip-syncing.  
- ğŸ™ï¸ **AI Voice Generation**: Utilizes **Eleven Labs' TTS** for high-quality voiceovers.  

3ï¸âƒ£ **Scene Merging for Extended Videos**  
- For videos up to **20 seconds**, we generate **up to 4 scenes** using a staged approach:  
  - The **last frame** of a scene is used as the **starting image** for the next scene.  
  - The scenes are **stitched together** to ensure a smooth transition.  

---

## ğŸ¥ Demo  

ğŸ”— **[Live Demo (if available)](https://your-demo-link.com)**  

ğŸ–¼ï¸ *(Optional: Add GIFs or screenshots showcasing generated video clips!)*  

---

## ğŸš€ Getting Started  

### ğŸ”§ Installation  

Clone the repo and install dependencies:  

```bash
git clone https://github.com/Ahmed14z/MovieLab.git
cd MovieLab
npm install
```

### â–¶ï¸ Run the App  

```bash
npm run dev
```

---

## ğŸ“Œ Tech Stack  

- **AI Models**:  
  - ğŸ–¼ï¸ **Image Analysis**: OpenAI Vision Model  
  - ğŸï¸ **Video Generation**: `fal-ai/kling-video/v1.6/pro/image-to-video`  
  - ğŸ—£ï¸ **Lip-Sync**: `fal-ai/latentsync`  
  - ğŸ™ï¸ **Text-to-Speech**: `Eleven Labs TTS`  

- **Backend**: Next.js  
- **Frontend**: Next.js  
- **Deployment**: Vercel, AWS / NHN Cloud  

---

## ğŸ’¡ Future Improvements  

ğŸš€ **Enhanced AI-Generated Camera Angles** â€“ More dynamic scene transitions.  
ğŸ­ **Emotional Speech & Expressions** â€“ Improve facial animations with emotion-based voice tones.  
ğŸ¨ **User-Uploaded Style Control** â€“ Allow users to define aesthetics and cinematography.  

---

## ğŸ† Hackathon Submission  

ğŸ¯ This project was built as part of **[Hackathon Name]** in [Month, Year].  

ğŸ¤– **Team Members**:  
- [Ahmed Mansy](https://github.com/Ahmed14z)  
- [Mohamed Magdy](https://github.com/MohamedMagdy097)  

ğŸ”— **Submission Link**: [Devpost / Hackathon Page](https://hackathon-submission-link.com)  

---

## ğŸ“œ License  

ğŸ“ This project is licensed under the [MIT License](LICENSE).  

---

ğŸ’¬ **Feedback? Contributions?**  
Feel free to open an **Issue** or submit a **Pull Request**! ğŸš€  

